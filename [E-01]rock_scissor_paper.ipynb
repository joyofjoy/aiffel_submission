{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3889bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1e59d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840  images to be resized.\n",
      "840  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.png\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"PNG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b291446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840  images to be resized.\n",
      "840  images resized.\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfccde7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840  images to be resized.\n",
      "840  images resized.\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651b8f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 2520 입니다.\n",
      "x_train shape: (2520, 28, 28, 4)\n",
      "y_train shape: (2520,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data= 2520):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=4\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0 # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dcba910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec3e7a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        2368      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 1,043,779\n",
      "Trainable params: 1,043,779\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,4)))\n",
    "model.add(keras.layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(128, (3,3), activation='relu',input_shape=(28,28,4)))\n",
    "model.add(keras.layers.Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286633e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "79/79 [==============================] - 3s 8ms/step - loss: 2.5043 - accuracy: 0.7234\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9806\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9976\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9988\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 0.9929\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.9988\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.6793e-04 - accuracy: 1.0000\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9992\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0435 - accuracy: 0.9869\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0227 - accuracy: 0.9933\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9873\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0900 - accuracy: 0.9778\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9913\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9948\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 0.9992\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0212 - accuracy: 0.9964\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 6.3159e-04 - accuracy: 0.9996\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.1804e-05 - accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 2.8831e-05 - accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9984\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 3.8319e-05 - accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 9.0105e-05 - accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 2.2928e-04 - accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3fcc235ac0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm=x_train.reshape( -1, 28, 28, 4) \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38becc12",
   "metadata": {},
   "source": [
    "## Test 돌리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ea55eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124  images to be resized.\n",
      "124  images resized.\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.png\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"PNG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0bd9cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124  images to be resized.\n",
      "124  images resized.\n",
      "124  images to be resized.\n",
      "124  images resized.\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3ec4619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터(x_test)의 이미지 개수는 372 입니다.\n",
      "x_test shape: (372, 28, 28, 4)\n",
      "y_test shape: (372,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=372):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=4\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트 데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eddd38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2931 - accuracy: 0.9032\n",
      "test_loss: 0.29312655329704285 \n",
      "test_accuracy: 0.9032257795333862\n"
     ]
    }
   ],
   "source": [
    "x_test_norm=x_test.reshape( -1, 28, 28, 4) \n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=1)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3284b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
